\section{Normalization factors, scale and PDFs}
\label{sec:normalization}

To be useful, our tabulation of cross sections must state the
underlying ``hard'' process, any kinematic cuts or kinematic assumptions,
the relevant set of parameters from the SM Lagrangian, the PDF set (or sets),
the scale choices, and the order of the electroweak (EW) and strong (QCD)
couplings in the perturbative expansion.
As a general rule, the ``best'' (usually highest-order) available calculation should be used when 
calculating cross-sections along with dependencies on kinematics. These predictions
may be used to normalize or reweight the Monte Carlo distributions in the analyses.
In doing so, generator level cuts which may have been used for a given Monte Carlo 
production should be taken into account also in the calculation of the K-factors. 
This requires that, for instance, the 
reference leading order (LO) parton shower based MC and the next-to-leading order 
(NLO) calculation should use as much as possible the same cuts, and similar PDFs. 
Applying an inclusive K-factor to a (LO) Monte Carlo generation implicitly assumes
that the change in acceptance introduced by the analysis is not very sensitive 
to higher order QCD effects. This is an aspect that should be checked carefully
by those analyses where such a sensitivity may be present. Alternatives to a
constant K-factor are an event reweighting, function of some kinematic variables, 
or a determination of an {\it a posteriori} K-factor, if the same acceptance cuts 
of the analysis can be reproduced at parton level for the higher order calculation.

Other inputs that should be made uniform between leading and higher order 
calculations are the normalization $\mu_R$ and factorization $\mu_F$ scales,
as well as the strong coupling constant and the PDFs. 
Additionally, the order of the PDFs used should match with the order of the 
matrix-element calculations in the ratio for the K-factors.

As a specific example to illustrate the subtleties that need consideration when 
deciding which higher-order calculation to apply to a given lower-order process, 
we will focus on $pp\to W^+ + X$ production. An inclusive 
prediction for the total cross section is available at NNLO in QCD.
% Steve:  (what order in EW?  mixed QCD-EW?).  
This calculation could be used to normalize a leading order calculation of 
$pp\to W^+ + X$ in an event generator with, ideally, the same choice of EW parameters 
used for the LO Monte Carlo. The first consideration is whether the treatment 
of the $W^+$ boson mass is consistent with the event generator, which most 
likely samples from a Breit-Wigner distribution. In cases like $pp\to Z+X$, it 
is important to note whether the ``Z'' boson includes a virtual photon, and, 
if so, the invariant mass window used in each calculation. They will clearly 
have to be match, which can be easily done provided that the ``higher-order'' 
corrections refer to QCD.

Some consideration of the kinematics is also in order. At NLO, the
complete calculation of $pp\to W^+ X$ includes the tree-level matrix elements
(MEs) for $q\bar q'\to W^+ g$, $qg\to W^+ q'$, and $\bar{q} g\to W^+ \bar{q}'$,
which produce a high-$p_T$ tail in the $W^+$ $p_T$ distribution.  
If the NLO normalization were applied to a parton shower calculation 
with $M_W$ as a cutoff on the parton virtualities, the resulting differential
distribution for $p_T(W^+)$ would be biased to low values. In some
analyses, when one is not directly observing $p_T(W^+)$, but is focused on
the $\ell^+$ decay lepton, this is not a concern. Fortunately, all modern
event generators include a ME-correction to the parton shower, so as to reproduce 
this high-$p_T$ tail.

At NNLO, the highest-order calculation available, a complete calculation
of $pp\to W^+ X$ includes $W^+$ + 2 parton final states.  Thus, 
the $gg\to W^+ q\bar q'$ MEs are included.  No such ME corrections
are available in vanilla event generators, but would be included in
a PS-ME ``matched'' MLM- or CKKW-like calculation (like the ones implemented
in generators like Alpgen~\cite{alpgen} or MadGraph~\cite{madgraph} or 
Sherpa~\cite{sherpa}). In practice, a
``matched'' calculation may contain more complicated topologies
than the best inclusive higher-order calculation. The mixture of
topologies will not match between the different calculations.
The kinematics of $q$ and $g$ jets may be different, and the different
radiation patterns could lead to different reconstruction efficiencies
and acceptances.  We view this as a subtle effect which will only become
important when systematic uncertainties in the analyses become smaller 
than the theoretical ones.

Another consideration is the choice of PDF.  Event generators are most
often used with LO PDFs.  The underlying event model tune, for example,
may be based on a LO PDF.   The same PDF is often used for determining
the kinematics of the LO partonic process, the initial state radiation (ISR)
parton showering, and the multiple-parton-interaction (MPI) model used to 
describe the underlying event activity. A standard NLO PDF would predict
a very different pattern of underlying event activity, for example.
Because the parton shower for $pp\to W^+ X$ includes a ME correction,
one may conclude that it is acceptable to use a LO PDF for this calculation
with a higher-order normalization.   This assumption may be wrong.
Surprisingly, in many relevant cases, the primary kinematic effect of a 
higher-order calculation originates from the NLO PDF.  The rapidity
of the $W^+$ boson, $y(W^+)$ is modeled quite accurately with
a LO ME + NLO PDF at LHC energies.  
% Roberto: citation needed here
On the other hand, the
rapidity of the $W^-$ or $Z$ boson is not as sensitive.

Thus, while the tables provided are useful for guidance,
some work is necessary to understand how to apply them.


\subsection{Scale uncertainties}
\label{kf}

The calculation of cross-sections in a given order in perturbation theory 
implies a dependence on both renormalization ($\mu_R$) and factorization 
($\mu_F$) scales. These are typically considered to be the same as the central 
value ($\mu_0$) of the scale.  For estimating the scale uncertainty, the scale 
choices are varied in the units of $\mu_0$ in an independent way. 
The uncertainty on the cross section given by the scale choices is
then conventionally determined by taking the maximum variation found in a 
range of scales $1/2 \mu_0 < \mu_R < 2\mu_0; 1/2 \mu_0 < \mu_F < 2\mu_0$. 

It is unclear if this choice of variation is conservative or liberal, and
it is to some extent arbitrary. Other prescriptions have been suggested
in literature~\cite{soper} but have so far been applied only
to inclusive jet production, with results not very different from the 
conventional ones.


\subsection{PDFs}
In general the most recent PDF sets should be used for cross section and 
acceptance calculations. If an analysis acceptance is studied using 
PYTHIA~\cite{Pythia} or HERWIG~\cite{Herwig}, the LO PDF (CTEQ6M~\cite{cteq6m} 
used in CMS simulations) should be used as a central value. However, the 
uncertainties on cross sections, and hence the uncertainties on acceptance, are 
computed with respect to the nominal choice at higher orders. %ROB confused: is that what you meant ???
We compute the PDF uncertainties using the prescription provided by the CTEQ 
Collaboration~\cite{cteq6m}. Additionally, the final systematics are computed using
the envelopes provided by the central values and PDF errors from the MSTW08~\cite{mstw08}, 
CTEQ6.6~\cite{cteq66} and NNPDF2.0~\cite{nnpdf} PDFs, using each group's prescriptions for 
combining the two types of errors.We use the PDF4LHC working group prescriptions~\cite{pdf4lhc}
to combine these uncertainties. In Appendix B we present this procedure in more detail,
along with the method we use to also incorporate $\alpha_S$ uncertainties in our
final error estimates. 

