\section{Data Samples}
\label{sec:datasamples}

The search is performed using the following datasets. The Monte Carlo (MC) cross sections
are normalized to the available Next-to-Leading-Order (NLO) or Next-to-Next-Leading-Order (NNLO) 
cross sections~\cite{xsection}. 

\begin{itemize}
\item Data 
\begin{itemize}
\item \verb=EG_Run2010A-Sep17ReReco_v2_RECO=
\item \verb=Electron-PromptReco-v2_RECO=
\item \verb=Mu_Run2010A-Sep17ReReco_v2_RECO=
\item \verb=Mu-PromptReco-v2_RECO=
\end{itemize}
\item Monte Carlo 
\begin{itemize}
\item \verb=TTbarJets-madgraph_Spring10-START3X_V26_S09-v1=
\item \verb=WJets-madgraph_Spring10-START3X_V26_S09-v1=
\item For Drell Yan we use a combination of:
\begin{enumerate}
\item \verb=ZJets-madgraph_Spring10-START3X_V26_S09-v1= for di-lepton mass $>50$\ GeV
\item \verb=Zee_Spring10-START3X_V26_S09-v1= for di-lepton mass from 20-50\ GeV
\item \verb=Zmumu_Spring10-START3X_V26_S09-v1= for di-lepton mass from 20-50\ GeV
\item \verb=Ztautau_Spring10-START3X_V26_S09-v1=  for di-lepton mass from 20-50\ GeV
\item \verb=DYee_M10to20_Spring10-START3X_V26_S09-v1=
\item \verb=DYmumu_M10to20_Spring10-START3X_V26_S09-v1=
\end{enumerate}
\item \verb=WW_Spring10-START3X_V26_S09-v1=
\item \verb=WZ_Spring10-START3X_V26_S09-v1=
\item \verb=ZZ_Spring10-START3X_V26_S09-v1=
\item \verb=SingleTop_tWChannel-madgraph_Spring10-START3X_V26_S09-v1=
\item \verb=SingleTop_tChannel-madgraph_Spring10-START3X_V26_S09-v1=
\item \verb=SingleTop_sChannel-madgraph_Spring10-START3X_V26_S09-v1=
\item \verb=LM0_Spring10-START3X_V26_S09-v1=
\item \verb=LM1_Spring10-START3X_V26_S09-v1=
\item \verb=PhotonVJets-madgraph_Spring10-START3X_V26_S09-v1=
\end{itemize}
\end{itemize}

The analysis is performed using the CMS certified JSON file covering run ranges
between 135821 to 149442 for an integrated luminosity of $35$ pb$^{-1}$. 

PYTHIA 6.4.22~\ref{pythia64} using MadEvent is used to generate the signal events for various choices of
$Z'$ masses. They are simulated using the FastSim model of the CMS detector and finally reconstructed 
and analyzed using the same software infrastructure as is used to process collision data.
