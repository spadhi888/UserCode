\section{Analysis}

This study aims to test if the results of three selected early CMS SUSY analyses are sufficient to impose visible constraints on the pMSSM parameter space, and consecutively on SUSY masses and low energy observables such as $(g-2)_\mu$, BR($b\rightarrow s\gamma$), etc.  To achieve this goal, we carry out the following analysis steps:
\begin{itemize}
\item We take 6K pMSSM points and generate 10K events for each point.
\item We perform the three selected CMS analyses, namely "di-jet $\alpha_T$", "opposite-sign di-lepton" and "same-sign di-lepton" on all of the 6K pMSSM samples
\item For each analysis, we combine the signal yield obtained from each pMSSM point with the observed data count and data-driven background estimate already available from the analysis results to compute likelihood functions
\item We weigh every pMSSM point with the product of the three likelihood functions obtained for three analysis for that point in order to input the CMS effect, and then calculate profile likelihoods for relevant model parameters.  We observe the effect of CMS results by comparing profile likelihood distributions weighted by the likelihood with those not weighted by the likelihood. 
\end{itemize}

\subsection{Event samples}

We use 6K pMSSM points from the set generated by Berger et. al. as explained in Section~\ref{sec:model}.  Information on each point is contained in a SUSY Les Houches (SLHA)~\cite{Skands:2003cj} file.  For each point, 10K events were generated using {\tt PYTHIA6}~\cite{Sjostrand:2006za}.  The generic detector simulation package {\tt Delphes}~\cite{Ovyn:2009tx} was used for simulating the CMS detector.  Through many numerical and shape comparisons {\tt Delphes} was shown to simulate CMS detector within 10\%, therefore it can be used reliably for the purposes of this analysis.

\subsection{Implementation of the three CMS analyses}

\begin{table}[htdp]
\caption{Comparison of signal Monte Carlo yields for the 3 CMS analyses}
\begin{center}
\begin{tabular}{|c|cc|cc|}
\hline
& \multicolumn{2}{|c|}{LM0} & \multicolumn{2}{|c|}{LM1} \\
\hline
& CMSSW & Delphes & CMSSW & Delphes \\
\hline
Dijet $\alpha_T$ & & & & \\
OS di-lepton & & & & \\
SS dil-epton & & & & \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}%


\begin{table}[htdp]
\caption{Numerical results of the three CMS analyses for $35~pb^{-1}$ as given by {\tt CMSSW} full simulation and {\tt Delphes} for the SUSY benchmarks LM0 and LM1.}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Analysis & Observed  & Data-driven SM & MC SM BG \\
              & data count & BG estimate      & prediction    \\
(k)          & ($N_k$)     & ($b_k \pm \delta b_k$) & ($b_k^{MC} \pm b_k^{MC}$) \\
\hline              
Dijet $\alpha_T$ & 14 & 11.4 $\pm$ 2.0 & 9.2 $\pm$ 0.9 \\
OS di-lepton & 1 & 2.1 $\pm$ 2.1 & 1.27 \\
SS di-lepton & 0 & 1.2 $\pm$ 0.8 & 0.35 \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}%



\subsection{Calculation of the likelihood based on CMS observation}

Every analysis $k$ yields an observed count $N_k$ and a background $b_k$ where $k=1,2,3$.  The total likelihood from the combination of the three analyses can be calculated as the products of the Poisson likelihoods for each analysis as
\begin{equation}
p(N|s,b) = \prod_{k=1}^3 Poisson(N_k|s_{k,i} + b_k)
\end{equation}
where $s_{k,i}$ is the predicted signal for the $i$th pMSSM point.  This likelihood is than used for weighting each pMSSM point when calculating the profile likelihood. 

\subsection{The profile likelihood method}

The profile likelihood method:
\begin{enumerate}
\item For each bin of the parameter or observable of interest we create a 19-dimensional histogram of the 6K points using TKDTreeBinning, which, through recursive binary partitioning, gives bins with equal bin content.
\item For a given bin, e.g. in input gluino mass parameter $M_3$, we find which of the 6K points is consistent with the given value of $M_3$ 
\item Using these points, we find the bin with the maximum density and use that as the profile likelihood value for the given value of $M_3$ 
\item In addition, in order to provide a better estimate, the above procedure is repeated 100 times, each with a different bootstrap sample of the original 6K points and the average is taken over the profiles in each bin. This in turn is done for each of the ~70 variables.
\end{enumerate}


